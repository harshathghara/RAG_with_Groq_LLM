# ğŸ” RAG-Based PDF Search Engine with LLM (Groq)

# Project Overview

RAG-Based PDF Search Engine with LLM (Groq)

This project is designed to search for relevant information within PDFs and generate intelligent responses using Groq's LLM. It follows a Retrieval-Augmented Generation (RAG) approach, which enhances the capabilities of LLMs by retrieving precise information from indexed document embeddings.

Here's how it works:

Text Extraction ğŸ“ â€“ Extracts text from PDFs using PyMuPDF.

Embedding Creation ğŸ”¢ â€“ Converts the text into embeddings using SentenceTransformers.

Vector Search ğŸ” â€“ Stores & retrieves embeddings via FAISS for fast lookups.

LLM Integration ğŸ¤– â€“ Uses Groq LLM to generate meaningful answers based on search results.

This makes it an efficient document retrieval system, helping users ask questions and get contextual responses from stored PDFs. Ideal for research, legal documents, or any large text-based datasets.

This project implements a **Retrieval-Augmented Generation (RAG) pipeline** that allows users to **search for information in PDF documents** using a **vector search engine (FAISS)** and an **LLM-powered response generation (Groq)**.

## ğŸš€ Features
- âœ… **Extracts text from PDFs** using `PyMuPDF`
- âœ… **Generates embeddings** using `SentenceTransformers`
- âœ… **Stores and retrieves vectors** using `FAISS`
- âœ… **Processes natural language queries**
- âœ… **Uses Groq LLM to generate responses**

---

## ğŸ—ï¸ Project Structure

ğŸ“‚ RAG_PDF_Search  
â”‚â”€â”€ ğŸ“‚ data/  
â”‚   â””â”€â”€ resume.pdf  # Your input PDF file 
â”‚   â””â”€â”€ Test.pdf  # Your input PDF file  
â”‚  
â”‚â”€â”€ ğŸ“‚ processed_text/  
â”‚   â””â”€â”€ resume.txt  # Extracted text from PDF  
|   â””â”€â”€ Test.txt  # Extracted text from PDF 
â”‚  
â”‚â”€â”€ ğŸ“‚ embeddings/  
â”‚   â”œâ”€â”€ faiss_index  # FAISS vector database  
â”‚   â”œâ”€â”€ faiss_index_metadata.npy  # Stores original text chunks 
â”‚   â”œâ”€â”€ faiss_index_for_Test  # FAISS vector database  
â”‚   â”œâ”€â”€ faiss_index_metadata_for_Test.npy  # Stores original text chunks  
â”‚  
â”‚â”€â”€ ğŸ“‚ src/  
â”‚   â”œâ”€â”€ extract_text.py  # Extract text from PDF  
â”‚   â”œâ”€â”€ generate_embeddings.py  # Generate & store embeddings in FAISS  
â”‚   â”œâ”€â”€ query_engine.py  # Interactive search engine  
â”‚   â”œâ”€â”€ llm_response.py   # Integrates LLM for responses
â”‚  
â”‚â”€â”€ ğŸ“œ requirements.txt  # Dependencies  
â”‚â”€â”€ ğŸ“œ README.md  # Project documentation  


---

## ğŸ”§ Setup Instructions
### 
1ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

2ï¸âƒ£ Extract Text from PDFs

python src/extract_text.py

3ï¸âƒ£ Generate FAISS Embeddings

python src/generate_embeddings.py

4ï¸âƒ£ Run the Query Engine

python src/query_engine.py

5ï¸âƒ£ Run LLM Response Generator

python src/llm_response.py

# ğŸ› ï¸ Future Enhancements


ğŸ”¹ Improve text cleaning for better retrieval

ğŸ”¹ Support multi-PDF search

ğŸ”¹ Optimize LLM prompt engineering


# Contributors ğŸ†

ğŸ‘¤ Harsh Kumar â€“ AI/ML Engineer
ğŸ“§ Email: harshathghara19@gmail.com